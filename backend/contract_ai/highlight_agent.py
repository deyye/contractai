import re
import json
from typing import Dict, List, Any, Optional, Tuple
from base_agent import BaseAgent

class HighlightAgent(BaseAgent):
    """Agent specialized in highlighting key points and important clauses"""
    
    def __init__(self):
        system_prompt = """ä½ æ˜¯ä¸“é—¨è¿›è¡Œé‡ç‚¹æ ‡æ³¨å’Œé«˜äº®çš„æ™ºèƒ½ä½“ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š

1. è¯†åˆ«åˆåŒä¸­çš„å…³é”®æ¡æ¬¾å’Œé‡è¦ä¿¡æ¯
2. æ ‡æ³¨æ½œåœ¨é£é™©ç‚¹å’Œæ³¨æ„äº‹é¡¹
3. çªå‡ºæ˜¾ç¤ºé‡è¦çš„è´¢åŠ¡æ¡æ¬¾
4. é«˜äº®æ³•å¾‹è´£ä»»å’Œä¹‰åŠ¡æ¡æ¬¾
5. æ ‡è®°æ—¶é—´æœŸé™å’Œæˆªæ­¢æ—¥æœŸ
6. æ³¨é‡Šä¸“ä¸šæœ¯è¯­å’Œå¤æ‚æ¡æ¬¾

é‡ç‚¹æ ‡æ³¨ç±»åˆ«ï¼š
- ğŸ”´ é«˜é£é™©æ¡æ¬¾ï¼šæ³•å¾‹é£é™©ã€è´¢åŠ¡é£é™©ã€å±¥è¡Œé£é™©
- ğŸŸ¡ ä¸­ç­‰å…³æ³¨ï¼šé‡è¦æ¡æ¬¾ã€ç‰¹æ®Šçº¦å®šã€é™åˆ¶æ¡ä»¶
- ğŸ”µ é‡è¦ä¿¡æ¯ï¼šå½“äº‹äººä¿¡æ¯ã€é‡‘é¢ã€æ—¥æœŸã€æœŸé™
- ğŸŸ¢ æœ‰åˆ©æ¡æ¬¾ï¼šæƒç›Šä¿æŠ¤ã€ä¼˜æƒ æ¡ä»¶ã€çµæ´»å®‰æ’
- âš ï¸ æ³¨æ„äº‹é¡¹ï¼šæ¨¡ç³Šè¡¨è¿°ã€äº‰è®®å¯èƒ½ã€åˆè§„è¦æ±‚

ä½ çš„æ ‡æ³¨åº”è¯¥ï¼š
- å‡†ç¡®è¯†åˆ«å…³é”®å†…å®¹
- ä½¿ç”¨ç»Ÿä¸€çš„æ ‡æ³¨ä½“ç³»
- æä¾›ç®€æ˜çš„æ³¨é‡Šè¯´æ˜
- ä¾¿äºç”¨æˆ·å¿«é€Ÿç†è§£é‡ç‚¹
- æ”¯æŒåç»­çš„å†³ç­–åˆ†æ"""

        super().__init__(agent_name="HighlightAgent", system_prompt=system_prompt)
        self.highlight_categories = self.initialize_highlight_categories()
    
    def initialize_highlight_categories(self) -> Dict[str, Dict[str, Any]]:
        """Initialize highlight categories and their criteria"""
        return {
            "é«˜é£é™©æ¡æ¬¾": {
                "color": "ğŸ”´",
                "keywords": ["è¿çº¦é‡‘", "èµ”å¿", "ç»ˆæ­¢", "è§£é™¤", "å…è´£", "ä¸å¯æ’¤é”€", "æ— æ¡ä»¶"],
                "patterns": [
                    r"è¿çº¦é‡‘.*?[\d,]+",
                    r"ä¸æ‰¿æ‹….*?è´£ä»»",
                    r"å•æ–¹.*?è§£é™¤",
                    r"æ— æ¡ä»¶.*?æ¥å—"
                ],
                "priority": 1
            },
            "è´¢åŠ¡æ¡æ¬¾": {
                "color": "ğŸ”µ",
                "keywords": ["é‡‘é¢", "è´¹ç”¨", "ä»·æ ¼", "æ”¯ä»˜", "é¢„ä»˜", "å°¾æ¬¾", "ä¿è¯é‡‘"],
                "patterns": [
                    r"[ï¿¥$Â¥]\s*[\d,]+(?:\.\d{2})?",
                    r"[\d,]+(?:\.\d{2})?\s*[å…ƒä¸‡åƒä¸‡äº¿]",
                    r"æ€»ä»·.*?[\d,]+",
                    r"é¢„ä»˜.*?[\d,]+"
                ],
                "priority": 2
            },
            "æ—¶é—´æ¡æ¬¾": {
                "color": "ğŸŸ¡",
                "keywords": ["æœŸé™", "æˆªæ­¢", "åˆ°æœŸ", "å®Œæˆæ—¶é—´", "äº¤ä»˜æ—¶é—´", "ç”Ÿæ•ˆæ—¥æœŸ"],
                "patterns": [
                    r"\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥",
                    r"\d{1,2}/\d{1,2}/\d{4}",
                    r"\d+å¤©å†…",
                    r"\d+ä¸ªå·¥ä½œæ—¥",
                    r"\d+ä¸ªæœˆå†…"
                ],
                "priority": 3
            },
            "æƒåˆ©ä¹‰åŠ¡": {
                "color": "ğŸŸ¢",
                "keywords": ["æƒåˆ©", "ä¹‰åŠ¡", "è´£ä»»", "ä¿è¯", "æ‰¿è¯º", "å£°æ˜"],
                "patterns": [
                    r"ç”²æ–¹.*?æƒåˆ©",
                    r"ä¹™æ–¹.*?ä¹‰åŠ¡",
                    r"æœ‰æƒ.*?è¦æ±‚",
                    r"åº”å½“.*?å±¥è¡Œ"
                ],
                "priority": 4
            },
            "äº‰è®®æ¡æ¬¾": {
                "color": "âš ï¸",
                "keywords": ["äº‰è®®", "çº çº·", "ä»²è£", "è¯‰è®¼", "ç®¡è¾–", "é€‚ç”¨æ³•å¾‹"],
                "patterns": [
                    r"äº‰è®®.*?è§£å†³",
                    r"ä»²è£.*?å§”å‘˜ä¼š",
                    r"ç®¡è¾–.*?æ³•é™¢",
                    r"é€‚ç”¨.*?æ³•å¾‹"
                ],
                "priority": 5
            },
            "ç‰¹æ®Šæ¡æ¬¾": {
                "color": "ğŸŸ¡",
                "keywords": ["ä¿å¯†", "ä¸å¯æŠ—åŠ›", "çŸ¥è¯†äº§æƒ", "è¿çº¦è´£ä»»", "ç»ˆæ­¢æ¡ä»¶"],
                "patterns": [
                    r"ä¿å¯†.*?ä¹‰åŠ¡",
                    r"ä¸å¯æŠ—åŠ›.*?äº‹ä»¶",
                    r"çŸ¥è¯†äº§æƒ.*?å½’å±",
                    r"æå‰.*?ç»ˆæ­¢"
                ],
                "priority": 6
            }
        }
    
    def process_text_message(self, message):
        """Process highlighting requests"""
        user_text = message
        self.logger.info("Processing highlight analysis request")
        
        try:
            # Extract task and content
            task_info = self.extract_task_info(user_text)
            document_content = task_info.get("content", user_text)
            
            # Perform highlighting analysis
            highlight_analysis = self.perform_highlight_analysis(document_content)
            
            # Format response
            response_text = self.format_highlight_results(highlight_analysis)
            
            return {
                "agent": "HighlightAgent",
                "status": "success",
                "analysis": highlight_analysis,
                "response_text": response_text,
                "timestamp": self._get_current_timestamp()
            }
            
        except Exception as e:
            self.logger.error(f"Error in highlight analysis: {str(e)}")
            return {
                "agent": "BusinessAgent",
                "status": "error",
                "message": f"é‡ç‚¹æ ‡æ³¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}",
                "response_text": "é‡ç‚¹æ ‡æ³¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ã€‚",
                "timestamp": self._get_current_timestamp()
            }
    
    def extract_task_info(self, text: str) -> Dict[str, Any]:
        """Extract task information from the input text"""
        lines = text.split('\n')
        task_info = {"content": text}
        
        for line in lines:
            if line.startswith("ä»»åŠ¡ï¼š"):
                task_info["task"] = line.replace("ä»»åŠ¡ï¼š", "").strip()
            elif line.startswith("ä¸Šä¸‹æ–‡ï¼š"):
                context_start = text.find("ä¸Šä¸‹æ–‡ï¼š")
                if context_start != -1:
                    task_info["content"] = text[context_start + 4:].strip()
                break
        
        return task_info
    
    def perform_highlight_analysis(self, document_text: str) -> Dict[str, Any]:
        """Perform comprehensive highlighting analysis"""
        analysis = {
            "highlighted_content": self.create_highlighted_content(document_text),
            "key_points": self.extract_key_points(document_text),
            "risk_highlights": self.identify_risk_highlights(document_text),
            "important_clauses": self.identify_important_clauses(document_text),
            "financial_highlights": self.extract_financial_highlights(document_text),
            "time_sensitive_items": self.extract_time_sensitive_items(document_text),
            "annotation_summary": self.create_annotation_summary(document_text),
            "highlight_statistics": {}
        }
        
        # Calculate highlight statistics
        analysis["highlight_statistics"] = self.calculate_highlight_statistics(analysis)
        
        # Get detailed analysis from LLM
        llm_analysis = self.get_llm_highlight_analysis(document_text)
        analysis["detailed_analysis"] = llm_analysis
        
        return analysis
    
    def create_highlighted_content(self, text: str) -> str:
        """Create highlighted version of the document"""
        highlighted_text = text
        highlight_count = 0
        
        # Process each highlight category
        for category_name, category_info in self.highlight_categories.items():
            color = category_info["color"]
            keywords = category_info["keywords"]
            patterns = category_info["patterns"]
            
            # Highlight keywords
            for keyword in keywords:
                # Find keyword occurrences in context
                pattern = rf'([^ã€‚ï¼›ï¼ï¼Ÿ]*{keyword}[^ã€‚ï¼›ï¼ï¼Ÿ]*[ã€‚ï¼›ï¼ï¼Ÿ]?)'
                
                def highlight_match(match):
                    nonlocal highlight_count
                    highlight_count += 1
                    return f"{color} **[{category_name}]** {match.group(1)}"
                
                highlighted_text = re.sub(pattern, highlight_match, highlighted_text)
            
            # Highlight specific patterns
            for pattern in patterns:
                def pattern_highlight(match):
                    nonlocal highlight_count
                    highlight_count += 1
                    return f"{color} **[{category_name}]** {match.group(0)}"
                
                highlighted_text = re.sub(pattern, pattern_highlight, highlighted_text)
        
        return highlighted_text
    
    def extract_key_points(self, text: str) -> List[Dict[str, Any]]:
        """Extract key points from the document"""
        key_points = []
        lines = text.split('\n')
        
        # Define importance indicators
        importance_keywords = {
            "å…³é”®ä¿¡æ¯": ["åˆåŒç¼–å·", "åˆåŒé‡‘é¢", "ç­¾ç½²æ—¥æœŸ", "ç”Ÿæ•ˆæ—¥æœŸ", "åˆ°æœŸæ—¥æœŸ"],
            "é‡è¦æ¡æ¬¾": ["è¿çº¦è´£ä»»", "äº‰è®®è§£å†³", "çŸ¥è¯†äº§æƒ", "ä¿å¯†æ¡æ¬¾", "ç»ˆæ­¢æ¡ä»¶"],
            "è´¢åŠ¡æ¡æ¬¾": ["æ”¯ä»˜æ–¹å¼", "ä»˜æ¬¾æœŸé™", "è¿çº¦é‡‘", "ä¿è¯é‡‘", "ä»·æ ¼è°ƒæ•´"],
            "å±¥è¡Œæ¡æ¬¾": ["äº¤ä»˜æ—¶é—´", "è´¨é‡æ ‡å‡†", "éªŒæ”¶æ ‡å‡†", "æœåŠ¡è¦æ±‚", "ç»´æŠ¤ä¹‰åŠ¡"]
        }
        
        for category, keywords in importance_keywords.items():
            for keyword in keywords:
                for i, line in enumerate(lines):
                    if keyword in line:
                        key_points.append({
                            "category": category,
                            "keyword": keyword,
                            "line_number": i + 1,
                            "content": line.strip(),
                            "importance": self.calculate_importance_score(line, keyword)
                        })
        
        # Sort by importance score
        key_points.sort(key=lambda x: x["importance"], reverse=True)
        
        return key_points[:20]  # Return top 20 key points
    
    def calculate_importance_score(self, text: str, keyword: str) -> int:
        """Calculate importance score for a text segment"""
        score = 5  # Base score
        
        # Increase score for financial amounts
        if re.search(r'[\d,]+[å…ƒä¸‡åƒä¸‡äº¿]', text):
            score += 3
        
        # Increase score for legal terms
        legal_terms = ["è¿çº¦", "è´£ä»»", "èµ”å¿", "äº‰è®®", "ç»ˆæ­¢", "è§£é™¤"]
        for term in legal_terms:
            if term in text:
                score += 2
                break
        
        # Increase score for time-sensitive content
        if re.search(r'\d+å¤©|\d+æœˆ|\d+å¹´|\d{4}-\d{2}-\d{2}', text):
            score += 2
        
        # Increase score for specific numbers or percentages
        if re.search(r'\d+%|\d+å€', text):
            score += 1
        
        # Decrease score for very short or very long lines
        if len(text) < 20 or len(text) > 200:
            score -= 1
        
        return max(score, 1)
    
    def identify_risk_highlights(self, text: str) -> List[Dict[str, Any]]:
        """Identify and highlight risk-related content"""
        risk_highlights = []
        
        # Define risk patterns and their severity
        risk_patterns = {
            "é«˜é£é™©": [
                (r"ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»", "è¿‡åº¦å…è´£æ¡æ¬¾"),
                (r"å•æ–¹é¢.*?å†³å®š", "å•æ–¹å†³å®šæƒ"),
                (r"æ— æ¡ä»¶.*?åŒæ„", "æ— æ¡ä»¶æ¥å—"),
                (r"è¿çº¦é‡‘.*?100%", "è¿‡é«˜è¿çº¦é‡‘"),
                (r"ç«‹å³.*?ç»ˆæ­¢", "å³æ—¶ç»ˆæ­¢é£é™©")
            ],
            "ä¸­é£é™©": [
                (r"å¸‚åœºä»·æ ¼.*?è°ƒæ•´", "ä»·æ ¼æ³¢åŠ¨é£é™©"),
                (r"ä¸å¯æŠ—åŠ›", "ä¸å¯æŠ—åŠ›æ¡æ¬¾"),
                (r"æå‰.*?é€šçŸ¥", "çŸ­æœŸé€šçŸ¥è¦æ±‚"),
                (r"ç¬¬ä¸‰æ–¹.*?è´£ä»»", "ç¬¬ä¸‰æ–¹è´£ä»»"),
                (r"ä¿å¯†.*?æœŸé™", "é•¿æœŸä¿å¯†ä¹‰åŠ¡")
            ],
            "ä½é£é™©": [
                (r"åå•†.*?è§£å†³", "åå•†è§£å†³æœºåˆ¶"),
                (r"åˆç†.*?è´¹ç”¨", "è´¹ç”¨æ‰¿æ‹…"),
                (r"åŒæ–¹.*?åŒæ„", "åŒæ–¹åŒæ„æ¡æ¬¾"),
                (r"æŒ‰ç…§.*?æ ‡å‡†", "æ ‡å‡†åŒ–è¦æ±‚")
            ]
        }
        
        for risk_level, patterns in risk_patterns.items():
            for pattern, description in patterns:
                matches = list(re.finditer(pattern, text))
                for match in matches:
                    # Get surrounding context
                    start = max(0, match.start() - 50)
                    end = min(len(text), match.end() + 50)
                    context = text[start:end]
                    
                    risk_highlights.append({
                        "risk_level": risk_level,
                        "description": description,
                        "matched_text": match.group(0),
                        "context": context,
                        "position": match.start(),
                        "severity_score": self.calculate_risk_severity(risk_level, description)
                    })
        
        # Sort by severity score
        risk_highlights.sort(key=lambda x: x["severity_score"], reverse=True)
        
        return risk_highlights
    
    def calculate_risk_severity(self, risk_level: str, description: str) -> int:
        """Calculate risk severity score"""
        base_scores = {"é«˜é£é™©": 9, "ä¸­é£é™©": 6, "ä½é£é™©": 3}
        score = base_scores.get(risk_level, 5)
        
        # Adjust based on description
        if "å…è´£" in description:
            score += 2
        elif "è¿çº¦é‡‘" in description:
            score += 2
        elif "ç»ˆæ­¢" in description:
            score += 1
        
        return min(score, 10)
    
    def identify_important_clauses(self, text: str) -> List[Dict[str, Any]]:
        """Identify important clauses that need attention"""
        important_clauses = []
        lines = text.split('\n')
        
        # Define clause importance indicators
        clause_indicators = {
            "æ ¸å¿ƒæ¡æ¬¾": [
                "åˆåŒæ ‡çš„", "æœåŠ¡å†…å®¹", "äº§å“è§„æ ¼", "å·¥ä½œèŒƒå›´", "é¡¹ç›®è¦æ±‚"
            ],
            "è´¢åŠ¡æ¡æ¬¾": [
                "åˆåŒä»·æ¬¾", "æ”¯ä»˜æ–¹å¼", "ä»˜æ¬¾æœŸé™", "è´¹ç”¨æ‰¿æ‹…", "ä»·æ ¼è°ƒæ•´"
            ],
            "å±¥è¡Œæ¡æ¬¾": [
                "å±¥è¡ŒæœŸé™", "äº¤ä»˜æ¡ä»¶", "éªŒæ”¶æ ‡å‡†", "è´¨é‡è¦æ±‚", "æœåŠ¡æ°´å¹³"
            ],
            "è´£ä»»æ¡æ¬¾": [
                "è¿çº¦è´£ä»»", "èµ”å¿è´£ä»»", "å…è´£æ¡ä»¶", "è´£ä»»é™åˆ¶", "è¿å¸¦è´£ä»»"
            ],
            "ç»ˆæ­¢æ¡æ¬¾": [
                "åˆåŒæœŸé™", "ç»ˆæ­¢æ¡ä»¶", "è§£é™¤æƒ", "æå‰ç»ˆæ­¢", "åˆåŒç»­æœŸ"
            ]
        }
        
        for clause_type, indicators in clause_indicators.items():
            for indicator in indicators:
                for i, line in enumerate(lines):
                    if indicator in line and len(line.strip()) > 10:
                        importance_score = self.calculate_clause_importance(line, clause_type)
                        
                        important_clauses.append({
                            "clause_type": clause_type,
                            "indicator": indicator,
                            "line_number": i + 1,
                            "content": line.strip(),
                            "importance_score": importance_score,
                            "requires_attention": importance_score >= 7
                        })
        
        # Remove duplicates and sort
        seen_lines = set()
        unique_clauses = []
        for clause in important_clauses:
            if clause["line_number"] not in seen_lines:
                unique_clauses.append(clause)
                seen_lines.add(clause["line_number"])
        
        unique_clauses.sort(key=lambda x: x["importance_score"], reverse=True)
        
        return unique_clauses[:15]  # Return top 15 important clauses
    
    def calculate_clause_importance(self, text: str, clause_type: str) -> int:
        """Calculate clause importance score"""
        score = 5  # Base score
        
        # Type-specific scoring
        type_scores = {
            "æ ¸å¿ƒæ¡æ¬¾": 8,
            "è´¢åŠ¡æ¡æ¬¾": 9,
            "å±¥è¡Œæ¡æ¬¾": 7,
            "è´£ä»»æ¡æ¬¾": 8,
            "ç»ˆæ­¢æ¡æ¬¾": 6
        }
        
        score = type_scores.get(clause_type, 5)
        
        # Content-based adjustments
        if re.search(r'å¿…é¡»|åº”å½“|ä¸å¾—|ç¦æ­¢', text):
            score += 1
        
        if re.search(r'[\d,]+[å…ƒä¸‡åƒä¸‡äº¿]', text):
            score += 2
        
        if re.search(r'è¿çº¦|èµ”å¿|æŸå¤±', text):
            score += 2
        
        if re.search(r'ç«‹å³|é©¬ä¸Š|å½“æ—¥|æ¬¡æ—¥', text):
            score += 1
        
        return min(score, 10)
    
    def extract_financial_highlights(self, text: str) -> List[Dict[str, Any]]:
        """Extract and highlight financial information"""
        financial_highlights = []
        
        # Financial patterns to highlight
        financial_patterns = [
            (r'[ï¿¥$Â¥]\s*[\d,]+(?:\.\d{2})?', "è´§å¸é‡‘é¢"),
            (r'[\d,]+(?:\.\d{2})?\s*[å…ƒä¸‡åƒä¸‡äº¿]', "ä¸­æ–‡é‡‘é¢"),
            (r'æ€»ä»·.*?([\d,]+)', "æ€»ä»·æ¡æ¬¾"),
            (r'å•ä»·.*?([\d,]+)', "å•ä»·æ¡æ¬¾"),
            (r'é¢„ä»˜.*?([\d,]+)', "é¢„ä»˜æ¬¾"),
            (r'ä¿è¯é‡‘.*?([\d,]+)', "ä¿è¯é‡‘"),
            (r'è¿çº¦é‡‘.*?([\d,]+)', "è¿çº¦é‡‘"),
            (r'(\d+)%.*?æŠ˜æ‰£', "æŠ˜æ‰£æ¯”ä¾‹"),
            (r'åˆ©ç‡.*?(\d+\.?\d*)%', "åˆ©ç‡æ¡æ¬¾")
        ]
        
        for pattern, description in financial_patterns:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                # Get surrounding context
                start = max(0, match.start() - 30)
                end = min(len(text), match.end() + 30)
                context = text[start:end]
                
                financial_highlights.append({
                    "type": description,
                    "amount": match.group(0),
                    "context": context,
                    "position": match.start(),
                    "priority": self.calculate_financial_priority(description, match.group(0))
                })
        
        # Sort by priority
        financial_highlights.sort(key=lambda x: x["priority"], reverse=True)
        
        return financial_highlights
    
    def calculate_financial_priority(self, description: str, amount: str) -> int:
        """Calculate financial highlight priority"""
        priority = 5  # Base priority
        
        # Higher priority for larger amounts
        amount_value = self.extract_numeric_value(amount)
        if amount_value:
            if amount_value >= 1000000:  # 100ä¸‡ä»¥ä¸Š
                priority += 3
            elif amount_value >= 100000:  # 10ä¸‡ä»¥ä¸Š
                priority += 2
            elif amount_value >= 10000:   # 1ä¸‡ä»¥ä¸Š
                priority += 1
        
        # Type-specific priorities
        type_priorities = {
            "æ€»ä»·æ¡æ¬¾": 9,
            "è¿çº¦é‡‘": 8,
            "ä¿è¯é‡‘": 7,
            "é¢„ä»˜æ¬¾": 7,
            "å•ä»·æ¡æ¬¾": 6,
            "è´§å¸é‡‘é¢": 5,
            "ä¸­æ–‡é‡‘é¢": 5,
            "æŠ˜æ‰£æ¯”ä¾‹": 4,
            "åˆ©ç‡æ¡æ¬¾": 6
        }
        
        type_priority = type_priorities.get(description, 5)
        priority = max(priority, type_priority)
        
        return min(priority, 10)
    
    def extract_numeric_value(self, amount_str: str) -> Optional[float]:
        """Extract numeric value from amount string"""
        try:
            # Remove currency symbols and spaces
            cleaned = re.sub(r'[ï¿¥$Â¥\s,]', '', amount_str)
            
            # Handle Chinese units
            if 'ä¸‡' in cleaned:
                number = re.search(r'([\d.]+)ä¸‡', cleaned)
                if number:
                    return float(number.group(1)) * 10000
            elif 'åƒ' in cleaned:
                number = re.search(r'([\d.]+)åƒ', cleaned)
                if number:
                    return float(number.group(1)) * 1000
            elif 'äº¿' in cleaned:
                number = re.search(r'([\d.]+)äº¿', cleaned)
                if number:
                    return float(number.group(1)) * 100000000
            
            # Extract regular numbers
            number = re.search(r'[\d.]+', cleaned)
            if number:
                return float(number.group(0))
            
        except (ValueError, AttributeError):
            pass
        
        return None
    
    def extract_time_sensitive_items(self, text: str) -> List[Dict[str, Any]]:
        """Extract time-sensitive items and deadlines"""
        time_items = []
        
        # Time patterns to highlight
        time_patterns = [
            (r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', "å…·ä½“æ—¥æœŸ"),
            (r'\d{1,2}/\d{1,2}/\d{4}', "æ—¥æœŸæ ¼å¼"),
            (r'(\d+)å¤©å†…', "å¤©æ•°æœŸé™"),
            (r'(\d+)ä¸ªå·¥ä½œæ—¥', "å·¥ä½œæ—¥æœŸé™"),
            (r'(\d+)ä¸ªæœˆå†…', "æœˆä»½æœŸé™"),
            (r'(\d+)å¹´å†…', "å¹´é™æœŸé™"),
            (r'æˆªæ­¢.*?(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)', "æˆªæ­¢æ—¥æœŸ"),
            (r'ä¸è¶…è¿‡.*?(\d+å¤©)', "æœ€é•¿æœŸé™"),
            (r'è‡ª.*?ä¹‹æ—¥èµ·.*?(\d+)', "èµ·ç®—æœŸé™")
        ]
        
        for pattern, description in time_patterns:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                # Get surrounding context
                start = max(0, match.start() - 40)
                end = min(len(text), match.end() + 40)
                context = text[start:end]
                
                time_items.append({
                    "type": description,
                    "time_expression": match.group(0),
                    "context": context,
                    "position": match.start(),
                    "urgency": self.calculate_time_urgency(description, match.group(0))
                })
        
        # Sort by urgency
        time_items.sort(key=lambda x: x["urgency"], reverse=True)
        
        return time_items
    
    def calculate_time_urgency(self, description: str, time_expr: str) -> int:
        """Calculate urgency score for time-sensitive items"""
        urgency = 5  # Base urgency
        
        # Extract time value
        time_value = re.search(r'\d+', time_expr)
        if time_value:
            value = int(time_value.group(0))
            
            if "å¤©" in time_expr:
                if value <= 7:
                    urgency += 4
                elif value <= 30:
                    urgency += 2
                elif value <= 90:
                    urgency += 1
            elif "å·¥ä½œæ—¥" in time_expr:
                if value <= 5:
                    urgency += 4
                elif value <= 20:
                    urgency += 2
            elif "æœˆ" in time_expr:
                if value <= 1:
                    urgency += 3
                elif value <= 6:
                    urgency += 1
        
        # Type-specific urgency
        if "æˆªæ­¢" in description:
            urgency += 3
        elif "æœ€é•¿" in description:
            urgency += 2
        
        return min(urgency, 10)
    
    def create_annotation_summary(self, text: str) -> Dict[str, Any]:
        """Create summary of all annotations"""
        summary = {
            "total_highlights": 0,
            "category_counts": {},
            "priority_distribution": {"é«˜": 0, "ä¸­": 0, "ä½": 0},
            "key_attention_areas": [],
            "recommended_actions": []
        }
        
        # Count highlights by category
        for category_name, category_info in self.highlight_categories.items():
            keywords = category_info["keywords"]
            patterns = category_info["patterns"]
            
            count = 0
            for keyword in keywords:
                count += len(re.findall(keyword, text))
            
            for pattern in patterns:
                count += len(re.findall(pattern, text))
            
            if count > 0:
                summary["category_counts"][category_name] = count
                summary["total_highlights"] += count
        
        # Identify key attention areas
        for category, count in summary["category_counts"].items():
            if count >= 3:
                summary["key_attention_areas"].append({
                    "area": category,
                    "mentions": count,
                    "recommendation": self.get_category_recommendation(category)
                })
        
        # Generate recommended actions
        if summary["category_counts"].get("é«˜é£é™©æ¡æ¬¾", 0) > 0:
            summary["recommended_actions"].append("é‡ç‚¹å…³æ³¨é«˜é£é™©æ¡æ¬¾ï¼Œå»ºè®®æ³•åŠ¡å®¡æ ¸")
        
        if summary["category_counts"].get("è´¢åŠ¡æ¡æ¬¾", 0) >= 3:
            summary["recommended_actions"].append("è´¢åŠ¡æ¡æ¬¾è¾ƒå¤šï¼Œå»ºè®®è´¢åŠ¡éƒ¨é—¨è¯¦ç»†å®¡æ ¸")
        
        if summary["category_counts"].get("æ—¶é—´æ¡æ¬¾", 0) >= 2:
            summary["recommended_actions"].append("æ³¨æ„æ—¶é—´æœŸé™è¦æ±‚ï¼Œå»ºè®®åˆ¶å®šå±¥è¡Œè®¡åˆ’")
        
        return summary
    
    def get_category_recommendation(self, category: str) -> str:
        """Get recommendation for specific category"""
        recommendations = {
            "é«˜é£é™©æ¡æ¬¾": "å»ºè®®è¯¦ç»†è¯„ä¼°é£é™©å½±å“ï¼Œå¿…è¦æ—¶å¯»æ±‚æ³•å¾‹å»ºè®®",
            "è´¢åŠ¡æ¡æ¬¾": "å»ºè®®è´¢åŠ¡éƒ¨é—¨å®¡æ ¸é‡‘é¢å’Œæ”¯ä»˜æ¡ä»¶çš„åˆç†æ€§",
            "æ—¶é—´æ¡æ¬¾": "å»ºè®®åˆ¶å®šè¯¦ç»†çš„æ—¶é—´è®¡åˆ’ï¼Œç¡®ä¿æŒ‰æœŸå±¥è¡Œ",
            "æƒåˆ©ä¹‰åŠ¡": "å»ºè®®ç¡®è®¤åŒæ–¹æƒåˆ©ä¹‰åŠ¡çš„å¹³è¡¡æ€§å’Œå¯æ‰§è¡Œæ€§",
            "äº‰è®®æ¡æ¬¾": "å»ºè®®è¯„ä¼°äº‰è®®è§£å†³æœºåˆ¶çš„é€‚ç”¨æ€§å’Œæœ‰æ•ˆæ€§",
            "ç‰¹æ®Šæ¡æ¬¾": "å»ºè®®é‡ç‚¹å…³æ³¨ç‰¹æ®Šçº¦å®šï¼Œç¡®ä¿ç†è§£å’Œæ‰§è¡Œ"
        }
        
        return recommendations.get(category, "å»ºè®®é‡ç‚¹å…³æ³¨æ­¤ç±»æ¡æ¬¾")
    
    def calculate_highlight_statistics(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate highlight statistics"""
        stats = {
            "total_key_points": len(analysis.get("key_points", [])),
            "risk_highlights_count": len(analysis.get("risk_highlights", [])),
            "important_clauses_count": len(analysis.get("important_clauses", [])),
            "financial_highlights_count": len(analysis.get("financial_highlights", [])),
            "time_sensitive_count": len(analysis.get("time_sensitive_items", [])),
            "high_priority_items": 0,
            "attention_score": 0
        }
        
        # Count high priority items
        for item in analysis.get("risk_highlights", []):
            if item.get("severity_score", 0) >= 8:
                stats["high_priority_items"] += 1
        
        for item in analysis.get("important_clauses", []):
            if item.get("importance_score", 0) >= 8:
                stats["high_priority_items"] += 1
        
        # Calculate attention score
        base_score = 5
        if stats["risk_highlights_count"] > 5:
            base_score += 2
        if stats["financial_highlights_count"] > 3:
            base_score += 1
        if stats["high_priority_items"] > 3:
            base_score += 2
        
        stats["attention_score"] = min(base_score, 10)
        
        return stats
    
    def get_llm_highlight_analysis(self, text: str) -> str:
        """Get detailed highlight analysis from LLM"""
        analysis_prompt = f"""
        è¯·å¯¹ä»¥ä¸‹åˆåŒæ–‡æœ¬è¿›è¡Œé‡ç‚¹æ ‡æ³¨åˆ†æï¼š
        
        åˆåŒæ–‡æœ¬ï¼š{text[:1500]}...
        
        è¯·è¯†åˆ«å¹¶åˆ†æï¼š
        1. æœ€é‡è¦çš„å…³é”®æ¡æ¬¾å’Œä¿¡æ¯ç‚¹
        2. éœ€è¦ç‰¹åˆ«æ³¨æ„çš„é£é™©ç‚¹
        3. é‡è¦çš„è´¢åŠ¡æ¡æ¬¾å’Œé‡‘é¢ä¿¡æ¯
        4. æ—¶é—´æ•æ„Ÿçš„æ¡æ¬¾å’ŒæœŸé™è¦æ±‚
        5. å¯èƒ½å­˜åœ¨äº‰è®®çš„æ¨¡ç³Šè¡¨è¿°
        6. å¯¹åˆåŒå±¥è¡Œè‡³å…³é‡è¦çš„æ¡æ¬¾
        
        è¯·æä¾›å…·ä½“çš„æ ‡æ³¨å»ºè®®å’Œæ³¨æ„äº‹é¡¹ã€‚
        """
        
        return self.call_llm(analysis_prompt)
    
    def format_highlight_results(self, analysis: Dict[str, Any]) -> str:
        """Format highlight analysis results for output"""
        output = "=== é‡ç‚¹æ ‡æ³¨åˆ†ææŠ¥å‘Š ===\n\n"
        
        # Statistics overview
        stats = analysis.get("highlight_statistics", {})
        output += f"æ€»ä½“å…³æ³¨åº¦ï¼š{stats.get('attention_score', 0)}/10\n"
        output += f"å…³é”®ç‚¹æ€»æ•°ï¼š{stats.get('total_key_points', 0)}\n"
        output += f"é«˜ä¼˜å…ˆçº§é¡¹ç›®ï¼š{stats.get('high_priority_items', 0)}\n\n"
        
        # Risk highlights
        risk_highlights = analysis.get("risk_highlights", [])
        if risk_highlights:
            output += "--- ğŸ”´ é£é™©æ ‡æ³¨ ---\n"
            for i, risk in enumerate(risk_highlights[:5], 1):
                output += f"{i}. [{risk['risk_level']}] {risk['description']}\n"
                output += f"   å†…å®¹ï¼š{risk['matched_text']}\n"
                output += f"   é£é™©è¯„åˆ†ï¼š{risk['severity_score']}/10\n\n"
        
        # Financial highlights
        financial_highlights = analysis.get("financial_highlights", [])
        if financial_highlights:
            output += "--- ğŸ’° è´¢åŠ¡æ ‡æ³¨ ---\n"
            for i, financial in enumerate(financial_highlights[:5], 1):
                output += f"{i}. {financial['type']}ï¼š{financial['amount']}\n"
                output += f"   ä¼˜å…ˆçº§ï¼š{financial['priority']}/10\n\n"
        
        # Time-sensitive items
        time_items = analysis.get("time_sensitive_items", [])
        if time_items:
            output += "--- â° æ—¶é—´æ ‡æ³¨ ---\n"
            for i, time_item in enumerate(time_items[:5], 1):
                output += f"{i}. {time_item['type']}ï¼š{time_item['time_expression']}\n"
                output += f"   ç´§æ€¥åº¦ï¼š{time_item['urgency']}/10\n\n"
        
        # Important clauses
        important_clauses = analysis.get("important_clauses", [])
        if important_clauses:
            output += "--- ğŸ“‹ é‡è¦æ¡æ¬¾ ---\n"
            for i, clause in enumerate(important_clauses[:5], 1):
                output += f"{i}. [{clause['clause_type']}] {clause['indicator']}\n"
                output += f"   é‡è¦æ€§ï¼š{clause['importance_score']}/10\n"
                if clause.get('requires_attention'):
                    output += f"   âš ï¸ éœ€è¦ç‰¹åˆ«æ³¨æ„\n"
                output += "\n"
        
        # Key points summary
        key_points = analysis.get("key_points", [])
        if key_points:
            output += "--- ğŸ”‘ å…³é”®ä¿¡æ¯ç‚¹ ---\n"
            categories = {}
            for point in key_points[:10]:
                category = point['category']
                if category not in categories:
                    categories[category] = []
                categories[category].append(point)
            
            for category, points in categories.items():
                output += f"\n{category}ï¼š\n"
                for point in points[:3]:  # Show top 3 per category
                    output += f"  â€¢ {point['keyword']} (é‡è¦æ€§: {point['importance']}/10)\n"
        
        # Annotation summary
        annotation_summary = analysis.get("annotation_summary", {})
        if annotation_summary:
            output += "\n--- ğŸ“Š æ ‡æ³¨ç»Ÿè®¡ ---\n"
            
            category_counts = annotation_summary.get("category_counts", {})
            for category, count in category_counts.items():
                output += f"{category}ï¼š{count}å¤„\n"
            
            key_areas = annotation_summary.get("key_attention_areas", [])
            if key_areas:
                output += "\né‡ç‚¹å…³æ³¨é¢†åŸŸï¼š\n"
                for area in key_areas:
                    output += f"  â€¢ {area['area']} ({area['mentions']}å¤„) - {area['recommendation']}\n"
            
            actions = annotation_summary.get("recommended_actions", [])
            if actions:
                output += "\nå»ºè®®è¡ŒåŠ¨ï¼š\n"
                for i, action in enumerate(actions, 1):
                    output += f"  {i}. {action}\n"
        
        # Detailed analysis
        detailed_analysis = analysis.get("detailed_analysis", "")
        if detailed_analysis:
            output += "\n--- ğŸ“ è¯¦ç»†æ ‡æ³¨åˆ†æ ---\n"
            output += detailed_analysis
        
        return output

if __name__ == "__main__":
    agent = HighlightAgent()